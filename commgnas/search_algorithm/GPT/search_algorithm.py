import json
import os
import re
import time
import math
import numpy as np
import requests
import heapq

import torch

from commgnas.parallel import ParallelOperater


class Search(object):
    def __init__(self, data, search_parameter, gnn_parameter, search_space):

        self.data = data
        self.iteration = int(search_parameter['iteration'])
        self.url = search_parameter['url']
        self.api_key = search_parameter['api_key']
        self.model = search_parameter['model']
        self.dataname = search_parameter['dataname']
        self.search_space = search_space
        self.stack_gcn_architecture = search_space.stack_gcn_architecture
        # parallel estimation operator initialize
        self.parallel_estimation = ParallelOperater(data, gnn_parameter)
    def experiments_prompt(self,arch_list, feedback_list, dataname):
        arch_list1 = arch_list[:-10]  # 从列表的开头开始（即索引 0），一直切片到倒数第 10 个元素之前（不包括倒数第 10 个元素）
        acc_list1 = feedback_list[:-10]
        arch_list3 = []  # 找出20个以上架构的前10名
        acc_list3 = []
        for i in (heapq.nlargest(10, range(len(acc_list1)), acc_list1.__getitem__)):
            arch_list3.append(arch_list1[i])
            acc_list3.append(acc_list1[i])

        arch_list2 = arch_list[-10:]  # 上一轮生成的10个架构
        acc_list2 = feedback_list[-10:]

        prompt1 = '''\nHere are some experimental results that you can use as a reference:\n'''
        # 性能要好于上一轮架构的平均性能
        prompt2 = ('''\nPlease propose 10 better models with feedback strictly greater than {}, which can improve the performance of the model on {} in addition to the experimental results mentioned above.\n'''
        .format(sum(feedback_list) / len(arch_list), dataname))  # 性能应大于已生成的平均性能
        # 不要生成重复模型
        prompt3 = '''\nThe model you propose should be strictly #different from the structure of the existing experimental results.#You should not raise the models that are already present in the above experimental results again.#\n'''

        if (len(arch_list) < 20):  # 总架构数少于20可以直接拼后面
            prompt_lastround = '''In the previous round of experiments, the models you provided me and their corresponding performance are as follows:\n{}''' \
                .format(''.join(
                ['Model [{}] achieves performance {:.4f}.\n'.format(arch, score) for
                 arch, score in
                 zip(arch_list, feedback_list)]))
            return prompt_lastround  # prompt_lastround + prompt2 + prompt3
        # 当架构数量多余20个时，
        prompt_lastround = '''In the previous round of experiments, the models you provided me and their corresponding performance are as follows:\n{}''' \
            .format(''.join(
            ['Model [{}] achieves performance {:.4f}.\n'.format(arch, score) for
             arch, score in
             zip(arch_list2, acc_list2)]))  # 上一轮的个数,可以省略
        prompt1 = prompt1 + '''{}#I hope you can learn the commonalities between the well performing models to achieve better results and avoid producing poor models.#\n''' \
            .format(''.join(
            ['Model [{}] achieves performance {:.4f}.\n'.format(arch, score) for
             arch, score in
             zip(arch_list3, acc_list3)]))
        return  prompt1 + prompt2  # prompt_lastround + prompt1 + prompt2 + prompt3

# The definition of search space for models follow the neighborhood aggregation schema, i.e., the Message Passing Neural Network (MPNN), which is formulated as:
#         {
#             $$\mathbf{m}_{v}^{k+1}=AGG_{k}(\{M_{k}(\mathbf{h}_{v}^{k}\mathbf{h}_{u}^{k},\mathbf{e}_{vu}^{k}):u\in N(v)\})$$
#             $$\mathbf{h}_{v}^{k+1}=ACT_{k}(COM_{k}(\{\mathbf{h}_{v}^{k},\mathbf{m}_{v}^{k+1}\}))$$
#         }
#         where $k$ denotes $k$-th layer, $N(v)$ denotes a set of neighboring nodes of $v$, $\mathbf{h}_{v}^{k}$, $\mathbf{h}_{u}^{k}$ denotes hidden embeddings for $v$ and $u$ respectively, $\mathrm{e}_{vu}^{k}$ denotes features for edge e(v, u) (optional), $\mathbf{m}_{v}^{k+1}$denotes the intermediate embeddings gathered from neighborhood $N(v)$, $M_k$ denotes the message function, $AGG_{k}$ denotes the neighborhood aggregation function, $COM_{k}$ denotes the combination function between intermediate embeddings and embeddings of node $v$ itself from the last layer, $ACT_{k}$ denotes activation function. Such message passing phase in repeats for $L$ times (i.e.,$ k\in\{1,\cdots,L\}$).
#


    def get_prompt(self,stage,arch_list,feedback_list):
        user_input = '''The task is to choose the optimal GNN architecture on ''' + self.dataname + ''' dataset, and the objective is to maximize model feedback, feedback reflects the performance of the model to a certain extent. Then use the node embedding matrix generated by the optimal architecture to complete the community detection task. 
        The components that need to be determined in the search space through architecture search, along with their corresponding candidate values are as follows：
        {
            Attention: [gat,gat_sym,gcn,const,generalized_linear,cos,linear];
            Aggregation: [sum,mean,max,mlp,mean,max,sum];
            Multi_heads: [1,2,4,4,6,8,16];
            Hidden_dimension: [8,16,32,64,128,256,64];
            Activation: [sigmoid,tanh,relu6,leaky_relu,softplus,elu,linear];
        }
        #For convenience, the candidate value corresponding to each component is represented by a number, ranging from #0 to 6#
        The model is a two-layer GNN model, take a model for example: the corresponding architecture of [3,1,3,5,2,6,0,3,3,1] is ['const','mean','4','256','relu6','linear','sum','4','64','tanh']
        '''
        notice1 = '''\n#Due to the lack of sufficient experimental results at present, it should be in the Exploration stage. You should focus more on exploring the entire search space evenly, rather than just focusing on the current local optimal results.#\n\n'''
        notice2 = '''\n#Due to the availability of a certain number of experimental results, I believe it is currently in the Exploitation stage. You should choose nearby samples that temporarily display the best results for searching, especially those that rank in the top 10% or 20% of existing experimental results. At the same time, you should try to avoid exploring sample structures with poor results, which can cause waste.#\n\n'''
        suffix = '''You should give 10 different models at a time, one model contains #10# operations. The value range corresponding to each operation must be between ###0 and 6###. Please do not include anything other than the operation list in your response. 
        The response you give must strictly follow the format of the following example :
            1.model: [3,1,0,4,1,4,5,3,1,4] 
            2.model: [5,6,4,3,2,2,3,4,6,0]
            3. ...
            ......
            10.model: [1,0,3,5,3,0,4,1,2,6]
            '''
        if (stage == 0):
            return user_input + notice1 + suffix
        elif (stage < 3):
            return user_input + self.experiments_prompt(arch_list, feedback_list, self.dataname)+ notice1 + suffix # 在prompt中加入上一轮最优的10个架构
        else:
            return user_input + self.experiments_prompt(arch_list, feedback_list, self.dataname) + notice2 + suffix

    def search_operator(self):  #初始化完开始运行搜索
        #搜索空间
        list2 = [{0: 'gat', 1: 'gat_sym', 2: 'gcn', 3: 'const', 4: 'generalized_linear', 5: 'cos', 6: 'linear'},
                 {0: 'sum', 1: 'mean', 2: 'max', 3: 'mlp', 4: 'mean', 5: 'max', 6: 'sum'},  # 输入为NAN
                 {0: '1', 1: '2', 2: '4', 3: '4', 4: '6', 5: '8', 6: '16'},
                 {0: '8', 1: '16', 2: '32', 3: '64', 4: '128', 5: '256', 6: '64'},  # 不要512 是否会出错
                 {0: 'sigmoid', 1: 'tanh', 2: 'relu6', 3: 'leaky_relu', 4: 'softplus', 5: 'elu', 6: 'linear'}]
        list4 = [6, 6, 6, 6, 6]
        headers = {
            "Content-Type": "application/json",
            "Authorization": "Bearer " + self.api_key
        }
        #文件路径
        #path = os.path.split(os.path.abspath(__file__))[0]
        root_directory =os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
        filename = '/history/gpt/' + self.dataname + '/'
        filename_message = root_directory+ filename + "massagev0.json"   #之后可以修改为时间
        filename_performance = root_directory + filename + "performancev0.json"
        #best_model = {"feedback": float('-inf'), "state_dict": None}
        #final_best_model = {"feedback": float('-inf'), "state_dict": None}
        performance_history = []
        messages_history = []
        arch_list = []
        feedback_list = []
        gnn_architecture_performance_dict = {}   #一一对应
        print(35 * "=", "search start", 35 * "=")
        time_initial = time.time()
        for iteration in range(self.iteration):
            prompt = self.get_prompt(iteration,arch_list,feedback_list)
            messages = [
                {"role": "system",
                 "content": '''You are a graph neural network architecture searcher,your goal is to select the GNN architecture with the highest loss change value on a given dataset to complete the community detection task. Pay special attention to the content in the special marker #.'''},
                {"role": "user", "content": prompt},
            ]
            da = {
                "model": self.model,
                "messages": messages,
                "temperature": 0
            }
            try:
                response = requests.post(self.url, headers=headers, data=json.dumps(da))
                response.raise_for_status()  # 检查请求是否成功
                res = response.json()
            except (requests.HTTPError, json.JSONDecodeError) as e:
                print("JSON parsing error:", e)
            except Exception as e:
                print("Other exceptions:", e)
            res_temp = res['choices'][0]['message']['content']
            print(res_temp)
            messages.append(res)
            messages_history.append(messages)
            with open(filename_message, "w") as f:  # 会自动创建
                json.dump(messages_history, f)
            arch_string = re.findall(r"\[.*?\]", res_temp)
            iter_list = []  # 当前架构
            for list in arch_string:
                list1 = eval(list)  # 转化为列表形式，
                # 检查列表中的值是否超出范围
                valid = self.is_list_valid(list1[:5], list4) and self.is_list_valid(list1[5:], list4)
                if not valid:
                    continue
                first = [list2[i][val] for i, val in enumerate(list1[:5])]
                second = [list2[j][val] for j, val in enumerate(list1[-5:])]
                list_value = first + second
                iter_list.append(list_value)  # 当前轮
                arch_list.append(list_value)
            result = self.parallel_estimation.estimation(iter_list)  #10个一起评估
            for arch, result_info in zip(iter_list, result):
            #best_arch, best_result = max(zip(iter_list, result), key=lambda x: x[1]["feedback"])  # 最佳架构及对应评估信息
                best_feedback = result_info["feedback"]
                best_L_1 = result_info["L_1"]
                best_M_1 = result_info["M_1"]
                best_S_1 = result_info["S_1"]
                best_L_2 = result_info["L_2"]
                best_M_2 = result_info["M_2"]
                best_S_2 = result_info["S_2"]
                with open(root_directory + filename + "iteration_" + self.dataname + "_new11.txt", "a+") as f:
                    f.write(str(iteration *10 ) + "." + str(
                        arch) + ": feedback:" + f"{best_feedback:.4f}" + " L_1:" + f"{best_L_1:.4f}" + " L_2:" + f"{best_L_2:.4f}" + " M_1:" + f"{best_M_1:.4f}" + " M_2:" + f"{best_M_2:.4f}" + " S_1:" + f"{best_S_1:.4f}" + " S_2:" + f"{best_S_2:.4f}" + "\n")
            for evaluation in result:
                feedback_list.append(evaluation["feedback"])

            for arch, feedback in zip(arch_list, feedback_list):
                performance_history.append({"arch": arch, "feedback": round(feedback, 4)})
            with open(filename_performance, "w") as f:  # 会自动创建
                json.dump(performance_history, f)
            #只记录每一轮feedback最大的模型
            # with open(logger_path + "/iteration_best_" + str(data_name) + "_new105_llama.txt", "a+") as f:
            #         f.write(str(arch) + ":" + f"{feedback:.4f}" + "\n")


        time_end=time.time() - time_initial
           #记录搜索时间 添加到

    def is_list_valid(self,list1, list2):
        for i in range(len(list2)):
            if list1[i] > list2[i]:
                return False
        return True



